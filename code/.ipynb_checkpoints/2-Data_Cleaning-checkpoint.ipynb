{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5 - Leveraging Social Media to Map Natural Disasters\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Imports](#Imports)\n",
    "2. [Read in Dataframes](#Read-in-Dataframes)\n",
    "3. [Data Cleaning](#Data-Cleaning)\n",
    "    1. [Creating Target Variable](#Creating-Target-Variable)\n",
    "    2. [Mapping Locations to Tweets](#Mapping-Locations-to-Tweets)\n",
    "4. [Export Clean Data](#Export-Clean-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup             \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Allows us to see whole cells (untruncated)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# setting a global random variable seed\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hurricane data\n",
    "hurricane = pd.read_csv('../datasets/hurricane_harvey.csv')\n",
    "# Load floods data\n",
    "floods = pd.read_csv('../datasets/floods.csv')\n",
    "# Load mudslides data\n",
    "mudslides = pd.read_csv('../datasets/mudslides.csv')\n",
    "# Load noreaster data\n",
    "noreaster = pd.read_csv('../datasets/noreaster.csv')\n",
    "# Load tornado data\n",
    "tornados = pd.read_csv('../datasets/tornados.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unncecessary columns from hurricane dataframe \n",
    "hurricane.drop(['Unnamed: 0', 'fullname', 'retweet_id', 'retweeter_userid', 'retweeter_username', \n",
    "    'timestamp', 'timestamp_epochs', 'tweet_id', 'user_id', 'username', 'dataframe'], axis = 1, inplace=True)\n",
    "\n",
    "# drop unncecessary columns from floods dataframe \n",
    "floods.drop(['Unnamed: 0', 'fullname', 'retweet_id', 'retweeter_userid', 'retweeter_username', \n",
    "    'timestamp', 'timestamp_epochs', 'tweet_id', 'user_id', 'username', 'html'], axis = 1, inplace=True)\n",
    "\n",
    "# drop unncecessary columns from mudslides dataframe \n",
    "mudslides.drop(['Unnamed: 0', 'fullname', 'retweet_id', 'retweeter_userid', 'retweeter_username', \n",
    "    'timestamp', 'timestamp_epochs', 'tweet_id', 'user_id', 'username'], axis = 1, inplace=True)\n",
    "\n",
    "# drop unncecessary columns from noreaster dataframe \n",
    "noreaster.drop(['Unnamed: 0', 'fullname', 'retweet_id', 'retweeter_userid', 'retweeter_username', \n",
    "    'timestamp', 'timestamp_epochs', 'tweet_id', 'user_id', 'username', 'html'], axis = 1, inplace=True)\n",
    "\n",
    "# drop unncecessary columns from tornados dataframe\n",
    "tornados.drop(['Unnamed: 0', 'fullname', 'retweet_id', 'retweeter_userid', 'retweeter_username', \n",
    "    'timestamp', 'timestamp_epochs', 'tweet_id', 'user_id', 'username', 'html'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column in each dataframe with the type of natural disaster it is\n",
    "hurricane['type'] = 'hurricane'\n",
    "floods['type'] = 'flood'\n",
    "mudslides['type'] = 'mudslide'\n",
    "noreaster['type'] = 'noreaster'\n",
    "tornados['type'] = 'tornado'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine dataframes\n",
    "df = pd.concat([hurricane, floods, mudslides, noreaster, tornados], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of new dataframe\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "#### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24061, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "df.drop_duplicates(subset='text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22901, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-check shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_retweet    1\n",
       "likes         1\n",
       "replies       1\n",
       "retweets      1\n",
       "text          1\n",
       "tweet_url     5\n",
       "type          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_retweet    0\n",
       "likes         0\n",
       "replies       0\n",
       "retweets      0\n",
       "text          0\n",
       "tweet_url     0\n",
       "type          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Romoving Unnecessary Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all tweets in the text column are strings\n",
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regext to remove unnecessary punctuation \n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r\"http\\S+\", \"\", x).lower())\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(r\"pic.twitter\\S+\", \"\", x))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub('[^ a-zA-Z!#911]','', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to remove links to other websites and picture links because we wanted to use just the pure text to train our model. Additionally we wanted to remove unnecessary punctuation except !, #, and the digits 911 because they either convey urgency or in the case of the hashtag it is widely used to get attention to your tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_words = ['fatality', 'destruction', 'rescue', 'stranded', 'stuck', 'injured', 'lost', 'dying', 'danger',\n",
    "              'medivac', 'sos', 'save me', 'save us', 'debris', 'injury', 'drowning', 'ambulance', 'doctor', \n",
    "              'help us', 'help me', 'fire', 'life-threatening', 'starving', 'broke', 'please help', 'ambulance', \n",
    "              '911', 'casualty', 'death', 'need help'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our target variable we must determine which tweets may constitute calls for emergency help. In order to categorize tweets we used a list of words that we decided would be used in a situation where an individual or group of individuals needed immediate help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency_tweets = [] \n",
    "for tweet in df['text']:\n",
    "    for word in critical_words:\n",
    "        if word in tweet: \n",
    "            emergency_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df[\"text\"].apply(lambda x: 1 if x in emergency_tweets else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20694\n",
       "1    2202 \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the classes are unbalanced but that is to be expected because the majority of tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Locations to the Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have assigned out target values, and we will now assign coordinates to each tweet. In an ideal scenario, this data would be able to be directly accessed from the tweets themselves, but due to out limited access to tweet information, these assumed cordinates will stand in as a proof-of-concept. <br>\n",
    "<br>\n",
    "Our targeted area of disaster occurence is going to be Houston, Texas. While our dataset was created from multiple disasters that happened in multiple cities around the US, we are going to simplify the visualization. The boundaries of the Houston area that we picked are:\n",
    "\n",
    "top left: 30.105670, -96.075520\n",
    "\n",
    "top right: 30.105670, -94.798950\n",
    "\n",
    "bottom left: 29.333485, -96.075520\n",
    "\n",
    "bottom right: 29.333485, -94.798950\n",
    "\n",
    "From these points, we can make our latitude and longitude boundaries to map tweets to. We will sample from a uniform distribution between these points to make our locations. As an additional layer of interest, our target tweets will be mapped in 6 different zones. 5 of them will be specific \"disaster zones\" to mark the hotspots of critical areas, and the sixth will be mapped throughout the full area in the same fashion as the null targets. The null targets, or tweets that are not in need of assistance, will be distributed across the entire area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Houston boundary coordinates\n",
    "total_area = {\n",
    "    \"lat\": [29.333485, 30.105670],\n",
    "    \"long\": [-96.243067, -94.798950]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing each disaster zone\n",
    "zone_1 = {\n",
    "    \"lat\": [29.777257, 30.020122],\n",
    "    \"long\": [-96.131424, -96.079262]\n",
    "}\n",
    "zone_2 = {\n",
    "    \"lat\": [29.752092, 29.784874],\n",
    "    \"long\": [-95.579720, -95.414298]\n",
    "}\n",
    "zone_3 = {\n",
    "    \"lat\": [29.993420, 30.031473],\n",
    "    \"long\": [-95.534265, -95.303653]\n",
    "}\n",
    "zone_4 = {\n",
    "    \"lat\": [29.859171, 29.884774],\n",
    "    \"long\": [-95.334881, -95.283405]\n",
    "}\n",
    "zone_5= {\n",
    "    \"lat\": [29.504332, 29.524648],\n",
    "    \"long\": [-95.128942, -95.017089]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the new coordinate columns\n",
    "df[\"latitude\"] = np.nan\n",
    "df[\"longitude\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The targets are going to be separated into different dataframes, have the locations asttached accordingly, and then will concatenated back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>praying for yall in texas! #hurricaneharvey</td>\n",
       "      <td>/RedSoxNation52/status/901232720713469952</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fyi #hurricaneharvey</td>\n",
       "      <td>/nataliereyy/status/901232720088637446</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my prayers goes to everyone in texas being affected by #hurricaneharvey please be safe and ok</td>\n",
       "      <td>/sothiachhoeum2/status/901232719312670720</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>#hurricaneharvey is coming we are bunkering down trying to save battery life will more than likely lose power prayers for our state xo</td>\n",
       "      <td>/tayslade/status/901232707455389696</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jim cantore is wearing a modded out baseball helmet on #theweatherchannel right now #safetyfirst #hurricaneharvey</td>\n",
       "      <td>/RebeccaBennitt/status/901232706247417856</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  is_retweet likes  replies  retweets  \\\n",
       "0  0      0.0         1     0.0      0.0        \n",
       "1  1      0.0         1     0.0      3.0        \n",
       "2  2      0.0         1     0.0      0.0        \n",
       "3  3      0.0         11    2.0      1.0        \n",
       "4  4      0.0         0     0.0      0.0        \n",
       "\n",
       "                                                                                                                                     text  \\\n",
       "0  praying for yall in texas! #hurricaneharvey                                                                                              \n",
       "1  fyi #hurricaneharvey                                                                                                                     \n",
       "2  my prayers goes to everyone in texas being affected by #hurricaneharvey please be safe and ok                                            \n",
       "3  #hurricaneharvey is coming we are bunkering down trying to save battery life will more than likely lose power prayers for our state xo   \n",
       "4  jim cantore is wearing a modded out baseball helmet on #theweatherchannel right now #safetyfirst #hurricaneharvey                        \n",
       "\n",
       "                                   tweet_url       type  target  latitude  \\\n",
       "0  /RedSoxNation52/status/901232720713469952  hurricane  0      NaN         \n",
       "1  /nataliereyy/status/901232720088637446     hurricane  0      NaN         \n",
       "2  /sothiachhoeum2/status/901232719312670720  hurricane  0      NaN         \n",
       "3  /tayslade/status/901232707455389696        hurricane  0      NaN         \n",
       "4  /RebeccaBennitt/status/901232706247417856  hurricane  0      NaN         \n",
       "\n",
       "   longitude  \n",
       "0 NaN         \n",
       "1 NaN         \n",
       "2 NaN         \n",
       "3 NaN         \n",
       "4 NaN         "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the dataframe into the two targets for easier mapping\n",
    "null_target = df[df[\"target\"] == 0]\n",
    "null_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>at  live at #hurricaneharvey plus local help on the way rescued tiger cub check up heatwave brings out snakes fire danger hs football</td>\n",
       "      <td>/KathleenFOX5/status/901232696533196800</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my heart is broken after hearing this praying for everyone in rockport #hurricaneharvey</td>\n",
       "      <td>/MariaPerezTW/status/901232218831544325</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uscoastguard rescues 1 from offshore supply ship near port mansfield  #rgv #rgvwx #hurricaneharvey</td>\n",
       "      <td>/BrownsvilleNews/status/901232121133617153</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>that code blue texas am cc just sent me felt like all hope is lost fuck you #hurricaneharvey</td>\n",
       "      <td>/robdoubleA/status/901232069170397185</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>maybe ted cruz will save us #hurricaneharvey  houston texas</td>\n",
       "      <td>/R_Phillip/status/901231724436361218</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  is_retweet likes  replies  retweets  \\\n",
       "6    6      0.0         2     0.0      0.0        \n",
       "172  192    0.0         0     0.0      0.0        \n",
       "197  217    0.0         1     0.0      0.0        \n",
       "213  233    0.0         12    0.0      7.0        \n",
       "289  310    0.0         0     0.0      0.0        \n",
       "\n",
       "                                                                                                                                       text  \\\n",
       "6    at  live at #hurricaneharvey plus local help on the way rescued tiger cub check up heatwave brings out snakes fire danger hs football    \n",
       "172  my heart is broken after hearing this praying for everyone in rockport #hurricaneharvey                                                  \n",
       "197  uscoastguard rescues 1 from offshore supply ship near port mansfield  #rgv #rgvwx #hurricaneharvey                                       \n",
       "213  that code blue texas am cc just sent me felt like all hope is lost fuck you #hurricaneharvey                                             \n",
       "289  maybe ted cruz will save us #hurricaneharvey  houston texas                                                                              \n",
       "\n",
       "                                      tweet_url       type  target  latitude  \\\n",
       "6    /KathleenFOX5/status/901232696533196800     hurricane  1      NaN         \n",
       "172  /MariaPerezTW/status/901232218831544325     hurricane  1      NaN         \n",
       "197  /BrownsvilleNews/status/901232121133617153  hurricane  1      NaN         \n",
       "213  /robdoubleA/status/901232069170397185       hurricane  1      NaN         \n",
       "289  /R_Phillip/status/901231724436361218        hurricane  1      NaN         \n",
       "\n",
       "     longitude  \n",
       "6   NaN         \n",
       "172 NaN         \n",
       "197 NaN         \n",
       "213 NaN         \n",
       "289 NaN         "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_target = df[df[\"target\"] == 1]\n",
    "pos_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelleadley/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/samuelleadley/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# applying random latitudes and longitudes to the null dataset\n",
    "null_target[\"latitude\"] = null_target[\"latitude\"].apply(\n",
    "    lambda x: round(np.random.uniform(total_area[\"lat\"][0], total_area[\"lat\"][1]), 6))\n",
    "\n",
    "null_target[\"longitude\"] = null_target[\"longitude\"].apply(\n",
    "    lambda x: round(np.random.uniform(total_area[\"long\"][0], total_area[\"long\"][1]), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>praying for yall in texas! #hurricaneharvey</td>\n",
       "      <td>/RedSoxNation52/status/901232720713469952</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>29.622699</td>\n",
       "      <td>-95.243400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>fyi #hurricaneharvey</td>\n",
       "      <td>/nataliereyy/status/901232720088637446</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>30.067612</td>\n",
       "      <td>-95.696869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my prayers goes to everyone in texas being affected by #hurricaneharvey please be safe and ok</td>\n",
       "      <td>/sothiachhoeum2/status/901232719312670720</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>29.898720</td>\n",
       "      <td>-95.837471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>#hurricaneharvey is coming we are bunkering down trying to save battery life will more than likely lose power prayers for our state xo</td>\n",
       "      <td>/tayslade/status/901232707455389696</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>29.795760</td>\n",
       "      <td>-95.285158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jim cantore is wearing a modded out baseball helmet on #theweatherchannel right now #safetyfirst #hurricaneharvey</td>\n",
       "      <td>/RebeccaBennitt/status/901232706247417856</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>0</td>\n",
       "      <td>29.453960</td>\n",
       "      <td>-94.826653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  is_retweet likes  replies  retweets  \\\n",
       "0  0      0.0         1     0.0      0.0        \n",
       "1  1      0.0         1     0.0      3.0        \n",
       "2  2      0.0         1     0.0      0.0        \n",
       "3  3      0.0         11    2.0      1.0        \n",
       "4  4      0.0         0     0.0      0.0        \n",
       "\n",
       "                                                                                                                                     text  \\\n",
       "0  praying for yall in texas! #hurricaneharvey                                                                                              \n",
       "1  fyi #hurricaneharvey                                                                                                                     \n",
       "2  my prayers goes to everyone in texas being affected by #hurricaneharvey please be safe and ok                                            \n",
       "3  #hurricaneharvey is coming we are bunkering down trying to save battery life will more than likely lose power prayers for our state xo   \n",
       "4  jim cantore is wearing a modded out baseball helmet on #theweatherchannel right now #safetyfirst #hurricaneharvey                        \n",
       "\n",
       "                                   tweet_url       type  target   latitude  \\\n",
       "0  /RedSoxNation52/status/901232720713469952  hurricane  0       29.622699   \n",
       "1  /nataliereyy/status/901232720088637446     hurricane  0       30.067612   \n",
       "2  /sothiachhoeum2/status/901232719312670720  hurricane  0       29.898720   \n",
       "3  /tayslade/status/901232707455389696        hurricane  0       29.795760   \n",
       "4  /RebeccaBennitt/status/901232706247417856  hurricane  0       29.453960   \n",
       "\n",
       "   longitude  \n",
       "0 -95.243400  \n",
       "1 -95.696869  \n",
       "2 -95.837471  \n",
       "3 -95.285158  \n",
       "4 -94.826653  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the new coords\n",
    "null_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the pos_target df into the different zones\n",
    "z1, z2, z3, z4, z5, z6 = np.split(pos_target, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the process of setting disaster zones easier, a function will be made that will take two lists, the dataframes, and the coordinate lists. This function will then attach the random zone coordinates accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a function to apply the random coordinates to each df\n",
    "def set_coord(df_list, coords_list):\n",
    "    \n",
    "    #looping through the df list while referencing indices\n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        # applying the random lat from the specificed zone\n",
    "        df[\"latitude\"] = df[\"latitude\"].apply(\n",
    "            lambda x: round(np.random.uniform(coords_list[i][\"lat\"][0], coords_list[i][\"lat\"][1]), 6))\n",
    "        \n",
    "        # applying the random long from the specified zone\n",
    "        df[\"longitude\"] = df[\"longitude\"].apply(\n",
    "            lambda x: round(np.random.uniform(coords_list[i][\"long\"][0], coords_list[i][\"long\"][1]), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of all the target zones\n",
    "target_zones = [z1, z2, z3, z4, z5, z6]\n",
    "\n",
    "# creating a list of all the coord zones\n",
    "coord_zones = [zone_1, zone_2, zone_3, zone_4, zone_5, total_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the function to assign the coordinates\n",
    "set_coord(target_zones, coord_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>at  live at #hurricaneharvey plus local help on the way rescued tiger cub check up heatwave brings out snakes fire danger hs football</td>\n",
       "      <td>/KathleenFOX5/status/901232696533196800</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>29.962051</td>\n",
       "      <td>-96.125356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my heart is broken after hearing this praying for everyone in rockport #hurricaneharvey</td>\n",
       "      <td>/MariaPerezTW/status/901232218831544325</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>29.814778</td>\n",
       "      <td>-96.102689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>uscoastguard rescues 1 from offshore supply ship near port mansfield  #rgv #rgvwx #hurricaneharvey</td>\n",
       "      <td>/BrownsvilleNews/status/901232121133617153</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>29.796093</td>\n",
       "      <td>-96.095140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>that code blue texas am cc just sent me felt like all hope is lost fuck you #hurricaneharvey</td>\n",
       "      <td>/robdoubleA/status/901232069170397185</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>29.930451</td>\n",
       "      <td>-96.110322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>maybe ted cruz will save us #hurricaneharvey  houston texas</td>\n",
       "      <td>/R_Phillip/status/901231724436361218</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>29.779674</td>\n",
       "      <td>-96.093268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  is_retweet likes  replies  retweets  \\\n",
       "6    6      0.0         2     0.0      0.0        \n",
       "172  192    0.0         0     0.0      0.0        \n",
       "197  217    0.0         1     0.0      0.0        \n",
       "213  233    0.0         12    0.0      7.0        \n",
       "289  310    0.0         0     0.0      0.0        \n",
       "\n",
       "                                                                                                                                       text  \\\n",
       "6    at  live at #hurricaneharvey plus local help on the way rescued tiger cub check up heatwave brings out snakes fire danger hs football    \n",
       "172  my heart is broken after hearing this praying for everyone in rockport #hurricaneharvey                                                  \n",
       "197  uscoastguard rescues 1 from offshore supply ship near port mansfield  #rgv #rgvwx #hurricaneharvey                                       \n",
       "213  that code blue texas am cc just sent me felt like all hope is lost fuck you #hurricaneharvey                                             \n",
       "289  maybe ted cruz will save us #hurricaneharvey  houston texas                                                                              \n",
       "\n",
       "                                      tweet_url       type  target   latitude  \\\n",
       "6    /KathleenFOX5/status/901232696533196800     hurricane  1       29.962051   \n",
       "172  /MariaPerezTW/status/901232218831544325     hurricane  1       29.814778   \n",
       "197  /BrownsvilleNews/status/901232121133617153  hurricane  1       29.796093   \n",
       "213  /robdoubleA/status/901232069170397185       hurricane  1       29.930451   \n",
       "289  /R_Phillip/status/901231724436361218        hurricane  1       29.779674   \n",
       "\n",
       "     longitude  \n",
       "6   -96.125356  \n",
       "172 -96.102689  \n",
       "197 -96.095140  \n",
       "213 -96.110322  \n",
       "289 -96.093268  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dfs for the new coordinates\n",
    "z1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 7 different dataframes, and need to bring them all back into one. They still all have the same columns, so they can simply be concatenated back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat-ing all the dfs\n",
    "df = pd.concat([null_target, z1, z2, z3, z4, z5, z6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20694\n",
       "1    2202 \n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the right target split\n",
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the tweets ended up empty because of regex so to avoid NaNs when reading the dataframe we removed them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exported cleaned data to datasets folder\n",
    "df.to_csv('../datasets/clean_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
